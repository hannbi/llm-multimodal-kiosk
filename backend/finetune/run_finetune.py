# finetune/run_finetune.py
# ---------------------------------------------
# ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ì•„ë˜ë¥¼ ìë™ìœ¼ë¡œ ìˆ˜í–‰í•©ë‹ˆë‹¤.
# 1) finetune/train.jsonl, finetune/valid.jsonl ì—…ë¡œë“œ
# 2) gpt-4o-mini-2024-07-18ì„ ë² ì´ìŠ¤ë¡œ íŒŒì¸íŠœë‹ Job ìƒì„±
# 3) Job ìƒíƒœë¥¼ ì£¼ê¸°ì ìœ¼ë¡œ ì¡°íšŒí•˜ì—¬ ì§„í–‰ ë¡œê·¸ ì¶œë ¥
# 4) ì™„ë£Œë˜ë©´ ëª¨ë¸IDë¥¼ finetune/model_id.txt ì— ì €ì¥
# ---------------------------------------------

import os
import time
from dotenv import load_dotenv
from openai import OpenAI

load_dotenv()

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

BASE_DIR = os.path.dirname(os.path.abspath(__file__))           # .../finetune
PROJECT_DIR = os.path.dirname(BASE_DIR)                         # í”„ë¡œì íŠ¸ ë£¨íŠ¸
TRAIN_PATH = os.path.join(BASE_DIR, "train.jsonl")
VALID_PATH = os.path.join(BASE_DIR, "valid.jsonl")
MODEL_ID_PATH = os.path.join(BASE_DIR, "model_id.txt")
BASE_MODEL = "gpt-4o-mini-2024-07-18"                           # ë² ì´ìŠ¤ ëª¨ë¸

def upload_file(path: str):
    if not os.path.exists(path):
        raise FileNotFoundError(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {path}")
    print(f"â¬†ï¸  ì—…ë¡œë“œ: {os.path.relpath(path, PROJECT_DIR)}")
    with open(path, "rb") as f:
        file = client.files.create(file=f, purpose="fine-tune")
    print(f"   â†’ file_id = {file.id}")
    return file.id

def create_job(train_file_id: str, valid_file_id: str):
    print("ğŸš€ íŒŒì¸íŠœë‹ Job ìƒì„± ì¤‘...")
    job = client.fine_tuning.jobs.create(
        training_file=train_file_id,
        validation_file=valid_file_id,
        model=BASE_MODEL,
        # í•„ìš”ì‹œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°ì • ê°€ëŠ¥
        # hyperparameters={"n_epochs":3, "batch_size":4, "learning_rate_multiplier":0.3}
    )
    print(f"   â†’ job_id = {job.id}")
    return job.id

def watch_job(job_id: str):
    print("ğŸ‘€ ì§„í–‰ìƒíƒœ ëª¨ë‹ˆí„°ë§ ì‹œì‘...")
    last_event_ts = 0
    while True:
        job = client.fine_tuning.jobs.retrieve(job_id)
        status = job.status
        # ìƒˆ ì´ë²¤íŠ¸ë§Œ ì¶œë ¥
        events = client.fine_tuning.jobs.list_events(job_id, limit=20)
        for ev in reversed(events.data):
            if ev.created_at and ev.created_at > last_event_ts:
                print(f"[{ev.created_at}] {ev.level.upper()} - {ev.message}")
                last_event_ts = ev.created_at

        if status in ("succeeded", "failed", "cancelled"):
            print(f"âœ… ìµœì¢… ìƒíƒœ: {status}")
            if status == "succeeded":
                ft_model = job.fine_tuned_model
                print(f"ğŸ‰ Fine-tuned Model ID: {ft_model}")
                # ëª¨ë¸ID ì €ì¥ (gpt_response.pyê°€ ìë™ìœ¼ë¡œ ì½ì–´ ì“°ë„ë¡)
                with open(MODEL_ID_PATH, "w", encoding="utf-8") as f:
                    f.write(ft_model)
                print(f"ğŸ’¾ ì €ì¥ë¨ â†’ {os.path.relpath(MODEL_ID_PATH, PROJECT_DIR)}")
            else:
                print("âš ï¸ íŒŒì¸íŠœë‹ì´ ì •ìƒ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            break

        time.sleep(3)  # ê³¼í•œ í˜¸ì¶œ ë°©ì§€ (ê°„ë‹¨ í´ë§)

def main():
    # 1) íŒŒì¼ ì—…ë¡œë“œ
    train_id = upload_file(TRAIN_PATH)
    valid_id = upload_file(VALID_PATH)

    # 2) Job ìƒì„±
    job_id = create_job(train_id, valid_id)
    print(f"ğŸ” ëŒ€ì‹œë³´ë“œì—ì„œë„ í™•ì¸ ê°€ëŠ¥ (Fine-tuning ë©”ë‰´) / job_id: {job_id}")

    # 3) ëª¨ë‹ˆí„°ë§
    watch_job(job_id)

if __name__ == "__main__":
    main()
